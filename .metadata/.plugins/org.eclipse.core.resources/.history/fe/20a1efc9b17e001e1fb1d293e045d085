package com.SpringBatch.Config;

import org.springframework.batch.core.configuration.annotation.EnableBatchProcessing;
import org.springframework.batch.item.file.FlatFileItemReader;
import org.springframework.batch.item.file.LineMapper;
import org.springframework.batch.item.file.mapping.DefaultLineMapper;
import org.springframework.batch.item.file.transform.DelimitedLineTokenizer;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.core.io.FileSystemResource;

import com.SpringBatch.entity.Customer;

@Configuration // this class is representative as batach processing.
@EnableBatchProcessing
public class BatchConfig {
	// item reader bean
	
	@Bean
	public FlatFileItemReader<Customer> customerReader(){
		
		FlatFileItemReader<Customer> itemReader = new FlatFileItemReader<>();
		itemReader.setResource(new FileSystemResource("src/main/resource/customers.csv"));
		itemReader.setName("customer-item-read");
		itemReader.setLinesToSkip(1);
		itemReader.setLineMapper(lineMapper());  // after this line it sugget to create the method. of linemapper.
		// it used to map the data to customer object mean from csv to entity.
		return itemReader;
		
	}

	private LineMapper<Customer> lineMapper() {
		
		DefaultLineMapper<Customer> lineMapper = new DefaultLineMapper<Customer>();
		DelimitedLineTokenizer lineTokenizer = new DelimitedLineTokenizer();
		lineTokenizer.setDelimiter(","); // this lines mean every data should separate by comma.
		lineTokenizer.setStrict(false); // this mean any value in csv that is emty that should consider null;
		return null;
	}
	
	
	
	
	
	// item processor bean
	// item writer bean
	// step bean 
	// job bean

}
